#!/usr/bin/env bash
# /usr/src/adm/scripts/30-fetcher
# -----------------------------------------------------------------------------
# ADM - Fetcher de fontes (HTTP/HTTPS/FTP/rsync/Git/GitHub/GitLab/SourceForge/dir)
# - Lê metafile
# - Baixa múltiplas URLs em paralelo, com retomada e verificação SHA256
# - Integra cache (15-cache-manager) quando disponível
# -----------------------------------------------------------------------------
set -Eeuo pipefail

: "${ADM_ROOT:=/usr/src/adm}"
: "${ADM_STATE:=$ADM_ROOT/state}"
: "${ADM_CACHE:=$ADM_ROOT/cache}"
: "${ADM_TMP:=${TMPDIR:-/tmp}}"

FETCH_STATE="$ADM_STATE/fetcher"
mkdir -p -- "$FETCH_STATE" "$ADM_CACHE" >/dev/null 2>&1 || true

# ============================== Logger (fallback) =============================
if ! command -v adm_log_info >/dev/null 2>&1; then
  _F_COLOR=${ADM_COLOR:-auto}
  _F_TTY=$([[ -t 1 ]] && echo true || echo false)
  if [[ "${NO_COLOR:-}" != "" ]]; then _F_COLOR=false; fi
  if [[ "$_F_COLOR" == "auto" ]]; then
    _F_COLOR=$([[ "$_F_TTY" == "true" ]] && echo true || echo false)
  fi
  if [[ "$_F_COLOR" == "true" ]]; then
    __f_red=$'\033[31m'; __f_grn=$'\033[32m'; __f_yel=$'\033[33m'
    __f_blu=$'\033[34m'; __f_mag=$'\033[35m'; __f_cyn=$'\033[36m'; __f_dim=$'\033[2m'; __f_rst=$'\033[0m'
  else
    __f_red=""; __f_grn=""; __f_yel=""; __f_blu=""; __f_mag=""; __f_cyn=""; __f_dim=""; __f_rst=""
  fi
  _f_ts(){ date +"%H:%M:%S"; }
  adm_log_debug(){ [[ "${ADM_DEBUG:-false}" == "true" ]] && printf "%s %b[DEBUG]%b %s\n" "$(_f_ts)" "$__f_dim" "$__f_rst" "$*" >&2 || true; }
  adm_log_info(){  printf "%s %b[INFO ]%b %s\n" "$(_f_ts)" "$__f_blu" "$__f_rst" "$*" >&2; }
  adm_log_warn(){  printf "%s %b[WARN ]%b %s\n" "$(_f_ts)" "$__f_yel" "$__f_rst" "$*" >&2; }
  adm_log_error(){ printf "%s %b[ERROR]%b %s\n" "$(_f_ts)" "$__f_red" "$__f_rst" "$*" >&2; }
  adm_log_success(){ printf "%s %b[SUCCESS]%b %s\n" "$(_f_ts)" "$__f_grn" "$__f_rst" "$*" >&2; }
fi

# ============================== Utils ========================================
_f_trim(){ printf "%s" "$(printf "%s" "$*" | sed -E 's/^[[:space:]]+|[[:space:]]+$//g')" ; }
_f_basename(){ basename -- "${1%%\?*}"; }
_f_sha256(){ sha256sum -- "$1" 2>/dev/null | awk '{print $1}'; }
_f_size(){ stat -c '%s' -- "$1" 2>/dev/null || stat -f '%z' -- "$1" 2>/dev/null || echo 0; }
_f_nproc(){ command -v nproc >/dev/null 2>&1 && nproc || getconf _NPROCESSORS_ONLN || echo 2; }
_f_downloader(){ command -v curl >/dev/null 2>&1 && echo curl || { command -v wget >/dev/null 2>&1 && echo wget || echo ""; }; }
_f_lockdir(){ local key="$1"; printf "%s" "$FETCH_STATE/locks/fetch-$key.lockdir"; }
_f_lock_acquire(){
  local key="$1"; mkdir -p -- "$FETCH_STATE/locks" || true
  local d="$(_f_lockdir "$key")"
  if mkdir "$d" 2>/dev/null; then :; else
    adm_log_warn "Esperando lock: $key"
    local t=0; while ! mkdir "$d" 2>/dev/null; do sleep 1; t=$((t+1)); ((t>300)) && { adm_log_error "Timeout lock $key"; return 1; } done
  fi
}
_f_lock_release(){ local key="$1"; rm -rf -- "$(_f_lockdir "$key")" 2>/dev/null || true; }

_f_key_from_url(){
  local u="$1" s="$2" fname="$3"
  if [[ -n "$s" ]]; then printf "sha256:%s" "$s"; return; fi
  local h; h="$(printf "%s" "$u" | sha256sum | awk '{print $1}')"
  [[ -n "$fname" ]] && printf "url:%s:%s" "$h" "$fname" || printf "url:%s" "$h"
}

_f_cmd_exists(){ command -v "$1" >/dev/null 2>&1; }

# ============================== Metafile parse ===============================
declare -A MF=()
_parse_metafile(){
  local file="$1"
  MF=()
  [[ -f "$file" ]] || { adm_log_error "Metafile não encontrado: %s" "$file"; return 1; }
  local line
  while IFS= read -r line || [[ -n "$line" ]]; do
    [[ -z "$line" || "$line" =~ ^[[:space:]]*# ]] && continue
    if [[ "$line" =~ ^([A-Za-z_][A-Za-z0-9_]*)=(.*)$ ]]; then
      MF["${BASH_REMATCH[1]}"]="$(_f_trim "${BASH_REMATCH[2]}")"
    else
      adm_log_warn "Linha ignorada em metafile: $(printf %q "$line")"
    fi
  done < "$file"
  # Normaliza arrays de sources e sha256sums
  IFS=',' read -r -a SOURCES <<< "${MF[sources]:-}"
  IFS=',' read -r -a SHAS <<< "${MF[sha256sums]:-}"
}

# ============================== Helpers de URL ===============================
_is_git_url(){
  local u="$1"
  [[ "$u" =~ ^(git\+|https://|http://|ssh://|git@).*\.git(/.*)?(@.+)?(#.*)?$ ]] && return 0
  [[ "$u" =~ ^git\+ ]] && return 0
  [[ "$u" =~ \.git(@|$) ]] && return 0
  return 1
}
_is_rsync_url(){ [[ "$1" =~ ^rsync:// ]] ; }
_is_ftp_url(){ [[ "$1" =~ ^ftp:// ]] ; }
_is_dir_path(){ [[ -d "$1" ]] ; }
_is_lftp_url(){ [[ "$1" =~ ^lftp\+ ]] ; }
_is_http_url(){ [[ "$1" =~ ^https?:// ]] ; }

# Shorthands:
_expand_github(){
  # github:user/repo@ref[#submodules=1]
  local u="$1"
  if [[ "$u" =~ ^github:([^/@]+)/([^@#]+)(@([^#]+))?(#.*)?$ ]]; then
    local user="${BASH_REMATCH[1]}" repo="${BASH_REMATCH[2]}" ref="${BASH_REMATCH[4]:-}"
    if [[ -n "$ref" ]]; then
      # usa tarball oficial por tag/branch
      printf "https://github.com/%s/%s/archive/refs/tags/%s.tar.gz" "$user" "$repo" "$ref"
    else
      # default main como tarball
      printf "https://github.com/%s/%s/archive/refs/heads/main.tar.gz" "$user" "$repo"
    fi
    return 0
  fi
  printf "%s" "$u"
}
_expand_gitlab(){
  # gitlab:group/repo@ref
  local u="$1"
  if [[ "$u" =~ ^gitlab:([^/@][^@#]*)/([^@#]+)(@([^#]+))?(#.*)?$ ]]; then
    local group="${BASH_REMATCH[1]}" repo="${BASH_REMATCH[2]}" ref="${BASH_REMATCH[4]:-main}"
    printf "https://gitlab.com/%s/%s/-/archive/%s/%s-%s.tar.gz" "$group" "$repo" "$ref" "$repo" "$ref"
    return 0
  fi
  printf "%s" "$u"
}
_expand_sourceforge(){
  # sf:project/path/to/file.tar.xz → downloads.sourceforge.net
  local u="$1"
  if [[ "$u" =~ ^sf: ]]; then
    u="${u#sf:}"
    printf "https://downloads.sourceforge.net/project/%s" "$u"
    return 0
  fi
  printf "%s" "$u"
}

_expand_shorthands(){
  local u="$1"
  u="$(_expand_github "$u")"
  u="$(_expand_gitlab "$u")"
  u="$(_expand_sourceforge "$u")"
  printf "%s" "$u"
}

# Extrai ref/submodules de URLs git-style
_git_parse_ref(){
  local u="$1"
  local ref=""
  if [[ "$u" =~ @(.*?)(#|$) ]]; then ref="${BASH_REMATCH[1]}"; fi
  printf "%s" "$ref"
}
_git_has_submodules(){
  local u="$1"
  [[ "$u" =~ \#.*submodules=1 ]] && return 0 || return 1
}

# ============================== Cache bridge =================================
_cache_fetch_source(){
  # usa 15-cache-manager se existir; senão baixa direto
  local url="$1" sha="$2" name="$3" ver="$4" cat="$5"
  local cm="$ADM_ROOT/scripts/15-cache-manager"
  if [[ -x "$cm" && "${FETCH_NO_CACHE:-0}" != "1" ]]; then
    "$cm" fetch-source --url="$url" ${sha:+--sha256="$sha"} ${name:+--name="$name"} ${ver:+--version="$ver"} ${cat:+--category="$cat"} \
      || return 1
    return 0
  fi
  # fallback: baixar agora e armazenar na cache localmente (sem index)
  local fname="$(_f_basename "$url")"
  local dest="$ADM_CACHE/sources/$fname"; mkdir -p -- "$(dirname "$dest")" || { adm_log_error "Sem acesso à cache local"; return 1; }
  _http_download "$url" "$dest" "$sha" || return 1
  return 0
}

# ============================== Downloaders ==================================
_http_download(){
  # $1=url $2=dest $3=sha (opcional)
  local url="$1" dest="$2" sha="${3:-}"
  local tmp="${dest}.partial"
  local dl; dl="$(_f_downloader)"
  [[ -z "$dl" ]] && { adm_log_error "Sem curl/wget para: $url"; return 1; }

  adm_log_info "HTTP(S)/FTP: $url"
  if [[ "$dl" == "curl" ]]; then
    local args=( -fL --retry 3 --retry-delay 2 -C - -o "$tmp" "$url" )
    curl "${args[@]}" || { adm_log_error "curl falhou: $url"; rm -f -- "$tmp" || true; return 1; }
  else
    local args=( -c - -O )
    args=( -c -O "$tmp" )
    wget "${args[@]}" "$url" || { adm_log_error "wget falhou: $url"; rm -f -- "$tmp" || true; return 1; }
  fi

  if [[ -n "$sha" ]]; then
    local got="$(_f_sha256 "$tmp")" || { adm_log_error "sha256sum falhou ($tmp)"; return 1; }
    if [[ "$got" != "$sha" ]]; then
      adm_log_error "SHA256 mismatch (got=$got expect=$sha) em $url"
      rm -f -- "$tmp" || true
      return 1
    fi
  fi
  mv -f -- "$tmp" "$dest" || { adm_log_error "Move falhou ($tmp → $dest)"; return 1; }
}

_lftp_download(){
  local url="$1" dest="$2" sha="${3:-}"
  local tmp="${dest}.partial"
  if _f_cmd_exists lftp; then
    adm_log_info "LFTP: $url"
    lftp -e "set net:timeout 30; set net:max-retries 3; pget -c -n 4 \"$url\" -o \"$tmp\"; bye" || { adm_log_error "lftp falhou"; rm -f -- "$tmp" || true; return 1; }
  else
    adm_log_warn "lftp indisponível; fallback para HTTP downloader"
    _http_download "${url#lftp+}" "$dest" "$sha" || return 1
    return 0
  fi
  if [[ -n "$sha" ]]; then
    local got="$(_f_sha256 "$tmp")"; [[ "$got" == "$sha" ]] || { adm_log_error "SHA256 mismatch lftp (got=$got expect=$sha)"; rm -f -- "$tmp" || true; return 1; }
  fi
  mv -f -- "$tmp" "$dest" || { adm_log_error "Move falhou ($tmp → $dest)"; return 1; }
}

_rsync_download(){
  local url="$1" destdir="$2"
  adm_log_info "RSYNC: $url"
  mkdir -p -- "$destdir" || { adm_log_error "Sem acesso a $destdir"; return 1; }
  rsync -av --partial --progress "$url" "$destdir/" || { adm_log_error "rsync falhou: $url"; return 1; }
}

_git_download_pack(){
  # Clona e empacota (tar.xz) para cache reprodutível
  local url="$1" ref="$2" submodules="$3" out_tar="$4"
  local work
  work="$(mktemp -d "${ADM_TMP%/}/gitfetch.XXXX")" || { adm_log_error "mktemp falhou"; return 1; }
  trap 'rm -rf -- "$work" 2>/dev/null || true' RETURN

  adm_log_info "GIT: $url ${ref:+(@$ref)}"
  git init -q "$work/repo" || { adm_log_error "git init falhou"; return 1; }
  git -C "$work/repo" remote add origin "$url" || { adm_log_error "git remote add falhou"; return 1; }
  if [[ -n "$ref" ]]; then
    git -C "$work/repo" fetch --depth=1 origin "$ref" || { adm_log_error "git fetch falhou (@$ref)"; return 1; }
    git -C "$work/repo" checkout -q FETCH_HEAD || { adm_log_error "git checkout falhou (@$ref)"; return 1; }
  else
    git -C "$work/repo" fetch --depth=1 origin || { adm_log_error "git fetch falhou"; return 1; }
    git -C "$work/repo" checkout -q FETCH_HEAD || { adm_log_error "git checkout falhou"; return 1; }
  fi
  if [[ "$submodules" == "1" ]]; then
    git -C "$work/repo" submodule update --init --recursive || { adm_log_warn "Submodules falharam (tolerado)"; }
  fi

  # tar.xz reprodutível
  (cd "$work/repo" && tar --sort=name --mtime='UTC 2020-01-01' --owner=0 --group=0 --numeric-owner -c . | xz -9eT0 > "$out_tar") \
    || { adm_log_error "Empacotamento tar.xz falhou"; return 1; }
  return 0
}

_dir_pack(){
  local dir="$1" out_tar="$2"
  adm_log_info "DIR: empacotando $dir → $(basename "$out_tar")"
  (cd "$dir" && tar --sort=name --mtime='UTC 2020-01-01' --owner=0 --group=0 --numeric-owner -c . | xz -9eT0 > "$out_tar") \
    || { adm_log_error "Empacotamento de diretório falhou"; return 1; }
}

# ============================== Worker =======================================
_fetch_one(){
  # $1=index  $2=url_raw  $3=sha_or_empty  $4=name  $5=ver  $6=cat
  local idx="$1" url_raw="$2" sha="$3" name="$4" ver="$5" cat="$6"
  [[ -z "$url_raw" ]] && { adm_log_warn "[$idx] URL vazia"; return 0; }

  local url; url="$(_expand_shorthands "$url_raw")"
  local fname="$(_f_basename "$url")"
  local outdir="$ADM_CACHE/sources"; mkdir -p -- "$outdir" || { adm_log_error "Sem acesso a $outdir"; return 1; }
  local dest="$outdir/$fname"

  local key; key="$(_f_key_from_url "$url" "$sha" "$fname")"
  _f_lock_acquire "$key" || return 1
  trap '_f_lock_release "'"$key"'"' RETURN

  # Se já existe e confere hash, reutiliza
  if [[ -f "$dest" && -n "$sha" ]]; then
    local got="$(_f_sha256 "$dest")" || true
    if [[ "$got" == "$sha" ]]; then
      adm_log_info "[$idx] Cache hit: $fname"
      return 0
    fi
  fi

  # Caminhos por tipo de URL
  if _is_lftp_url "$url"; then
    _lftp_download "$url" "$dest" "$sha" || return 1

  elif _is_rsync_url "$url"; then
    local dstd="$ADM_CACHE/sources/rsync_${idx}_$(date +%s)"
    _rsync_download "$url" "$dstd" || return 1
    # opcional: empacotar diretório rsync
    local tar="$dest.tar.xz"
    _dir_pack "$dstd" "$tar" || return 1
    mv -f -- "$tar" "$dest.tar.xz"
    dest="$dest.tar.xz"

  elif _is_git_url "$url"; then
    local ref; ref="$(_git_parse_ref "$url")"
    local subs=0; _git_has_submodules "$url" && subs=1
    # normaliza url sem decoradores
    local clean="${url%%@*}"; clean="${clean%%#*}"
    local tar="$dest.tar.xz"
    _git_download_pack "$clean" "$ref" "$subs" "$tar" || return 1
    dest="$tar"
    if [[ -n "$sha" ]]; then
      local got="$(_f_sha256 "$dest")"; [[ "$got" == "$sha" ]] || { adm_log_error "SHA mismatch (git pack): got=$got exp=$sha"; return 1; }
    fi

  elif _is_dir_path "$url"; then
    # Fonte local (diretório), empacotar para cache
    local tar="$dest.tar.xz"
    _dir_pack "$url" "$tar" || return 1
    dest="$tar"
    if [[ -n "$sha" ]]; then
      local got="$(_f_sha256 "$dest")"; [[ "$got" == "$sha" ]] || { adm_log_error "SHA mismatch (dir pack): got=$got exp=$sha"; return 1; }
    fi

  elif _is_http_url "$url" || _is_ftp_url "$url"; then
    # Tenta via cache-manager (reuso + verify), senão baixa
    if [[ "${FETCH_NO_CACHE:-0}" != "1" ]] && [[ -x "$ADM_ROOT/scripts/15-cache-manager" ]]; then
      "$ADM_ROOT/scripts/15-cache-manager" fetch-source --url="$url" ${sha:+--sha256="$sha"} \
        ${name:+--name="$name"} ${ver:+--version="$ver"} ${cat:+--category="$cat"} \
        || { adm_log_warn "cache-manager falhou; baixando direto"; _http_download "$url" "$dest" "$sha" || return 1; }
    else
      _http_download "$url" "$dest" "$sha" || return 1
    fi

  else
    adm_log_error "[$idx] Esquema não suportado: $url_raw"
    return 1
  fi

  adm_log_success "[$idx] OK: $(basename -- "$dest") (~$(_f_size "$dest") bytes)"
}
# (continuação do arquivo /usr/src/adm/scripts/30-fetcher)

# ============================== Orquestração =================================

_fetch_parallel(){
  # Recebe listas SOURCES[] e SHAS[] já carregadas. Dispara paralelo limitado.
  local name="$1" ver="$2" cat="$3" force="${4:-0}" jobs="${5:-}"
  local total="${#SOURCES[@]}"; (( total==0 )) && { adm_log_warn "Nenhuma fonte em sources="; return 0; }

  local max_jobs
  if [[ -n "$jobs" ]]; then max_jobs="$jobs"; else
    # heurística: núcleos/2, mínimo 2, máximo 8
    local np=$(_f_nproc); max_jobs=$(( np/2 )); ((max_jobs<2)) && max_jobs=2; ((max_jobs>8)) && max_jobs=8
    [[ -n "${FETCH_JOBS:-}" ]] && max_jobs="${FETCH_JOBS}"
  fi

  adm_log_info "Baixando $total fonte(s) em até $max_jobs tarefas…"

  # controla fila manualmente (compatível POSIX)
  local running=0 idx
  local -a pids=()
  local failures=0

  for ((idx=0; idx<total; idx++)); do
    local u="$(_f_trim "${SOURCES[$idx]}")"; [[ -z "$u" ]] && continue
    local sha=""; [[ $idx -lt ${#SHAS[@]} ]] && sha="$(_f_trim "${SHAS[$idx]}")"

    # Força recarregar? (apenas remove destino provável)
    if [[ "$force" == "1" ]]; then
      local fname="$(_f_basename "$(_expand_shorthands "$u")")"
      rm -f -- "$ADM_CACHE/sources/$fname" "$ADM_CACHE/sources/$fname.tar.xz" 2>/dev/null || true
    fi

    (
      # sub-shell do worker
      set -Eeuo pipefail
      _fetch_one "$((idx+1))" "$u" "$sha" "$name" "$ver" "$cat"
    ) & pids+=($!)
    running=$((running+1))

    if (( running >= max_jobs )); then
      if ! wait -n 2>/dev/null; then failures=$((failures+1)); fi
      running=$((running-1))
    fi
  done

  # aguarda restantes
  local pid
  for pid in "${pids[@]}"; do
    if ! wait "$pid"; then failures=$((failures+1)); fi
  done

  (( failures>0 )) && { adm_log_error "Falhas em $failures download(s)."; return 1; }
  adm_log_success "Todos os downloads concluídos."
  return 0
}

# ============================== CLI ==========================================

fetcher_usage(){
  cat <<'USAGE'
Uso: 30-fetcher fetch --metafile=/path/to/metafile [opções]

Opções:
  --force           Ignora artefatos existentes na cache e baixa novamente.
  --no-cache        Não usa 15-cache-manager (baixa direto).
  --jobs=N          Paralelismo máximo (padrão: heurística).
  --name= --version= --category=  (override dos campos do metafile)
  --only=idx1,idx2  Baixa apenas índices específicos da lista de sources (1-based).

Notas:
- Aceita URLs: http(s):// ftp:// lftp+ftp:// rsync:// git(.git|git+…|@ref|#submodules=1)
- Shorthands:
    github:user/repo@v1.2.3
    gitlab:group/sub/repo@v1.2.3
    sf:project/path/to/file.tar.xz
- Diretório local em sources= é empacotado em tar.xz reprodutível.
- sha256sums= pode ter 0..N itens. Quando presente, mapeia por índice.

Exemplos:
  30-fetcher fetch --metafile=/usr/src/adm/metafiles/apps/busybox/metafile --jobs=4
  FETCH_JOBS=8 30-fetcher fetch --metafile=./metafile
  30-fetcher fetch --metafile=./metafile --only=1,3
USAGE
}

_fetch_only_filter(){
  local list="$1" total="$2"
  [[ -z "$list" ]] && { echo ""; return 0; }
  local -a keep=()
  IFS=',' read -r -a arr <<< "$list"
  local x
  for x in "${arr[@]}"; do
    [[ "$x" =~ ^[0-9]+$ ]] || { adm_log_warn "--only: índice inválido '$x'"; continue; }
    (( x>=1 && x<=total )) && keep+=("$x") || adm_log_warn "--only: fora de faixa '$x'"
  done
  printf "%s " "${keep[@]}"
}

fetcher_fetch(){
  local metafile="" force=0 nocache=0 jobs="" onlies=""
  local name_override="" ver_override="" cat_override=""
  while (( $# )); do
    case "$1" in
      --metafile=*) metafile="${1#--metafile=}" ;;
      --force) force=1 ;;
      --no-cache) nocache=1 ;;
      --jobs=*) jobs="${1#--jobs=}" ;;
      --name=*) name_override="${1#--name=}" ;;
      --version=*) ver_override="${1#--version=}" ;;
      --category=*) cat_override="${1#--category=}" ;;
      --only=*) onlies="${1#--only=}" ;;
      *) adm_log_warn "Arg ignorado: $1" ;;
    esac; shift || true
  done
  [[ -n "$metafile" ]] || { adm_log_error "Uso: fetch --metafile=…"; return 2; }

  FETCH_NO_CACHE="$nocache" export FETCH_NO_CACHE

  _parse_metafile "$metafile" || return 1
  local name="${name_override:-${MF[name]:-}}"
  local ver="${ver_override:-${MF[version]:-}}"
  local cat="${cat_override:-${MF[category]:-}}"

  [[ -n "$name" && -n "$ver" ]] || adm_log_warn "Metafile sem name/version — seguindo assim mesmo."

  # Filtra índices (--only)
  if [[ -n "$onlies" ]]; then
    local keeps; keeps="$(_fetch_only_filter "$onlies" "${#SOURCES[@]}")"
    if [[ -n "$keeps" ]]; then
      local -a S2=() H2=() ; local i=1 s
      for s in "${SOURCES[@]}"; do
        if grep -qw -- "$i" <<< "$keeps"; then S2+=("$s"); [[ $((i-1)) -lt ${#SHAS[@]} ]] && H2+=("${SHAS[$((i-1))]}"); fi
        i=$((i+1))
      done
      SOURCES=("${S2[@]}"); SHAS=("${H2[@]}")
    else
      adm_log_warn "--only não resultou em itens; nada a fazer."; return 0
    fi
  fi

  _fetch_parallel "$name" "$ver" "$cat" "$force" "$jobs"
}

fetcher_main(){
  local cmd="${1:-}"; shift || true
  case "$cmd" in
    fetch) fetcher_fetch "$@" ;;
    ""|-h|--help|help) fetcher_usage ;;
    *) adm_log_error "Comando desconhecido: $cmd"; fetcher_usage; exit 2 ;;
  esac
}

if [[ "${BASH_SOURCE[0]}" == "$0" ]]; then
  fetcher_main "$@"
fi
